{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, Normalizer\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "\n",
    "# Supress unnecessary warnings so that presentation looks clean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>f1</th>\n",
       "      <th>f2</th>\n",
       "      <th>gen</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.417022</td>\n",
       "      <td>0.720324</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.302333</td>\n",
       "      <td>0.146756</td>\n",
       "      <td>0.092339</td>\n",
       "      <td>0.186260</td>\n",
       "      <td>0.345561</td>\n",
       "      <td>0.396767</td>\n",
       "      <td>0.538817</td>\n",
       "      <td>0.417022</td>\n",
       "      <td>2.482199</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.678836</td>\n",
       "      <td>0.211628</td>\n",
       "      <td>0.265547</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.053363</td>\n",
       "      <td>0.574118</td>\n",
       "      <td>0.146729</td>\n",
       "      <td>0.589306</td>\n",
       "      <td>0.699758</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>4.408805</td>\n",
       "      <td>1</td>\n",
       "      <td>63.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.028306</td>\n",
       "      <td>0.246211</td>\n",
       "      <td>0.860028</td>\n",
       "      <td>0.538831</td>\n",
       "      <td>0.552822</td>\n",
       "      <td>0.842031</td>\n",
       "      <td>0.124173</td>\n",
       "      <td>0.279184</td>\n",
       "      <td>0.019880</td>\n",
       "      <td>4.198771</td>\n",
       "      <td>1</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0.556240</td>\n",
       "      <td>0.136455</td>\n",
       "      <td>0.059918</td>\n",
       "      <td>0.121343</td>\n",
       "      <td>0.044552</td>\n",
       "      <td>0.107494</td>\n",
       "      <td>0.225709</td>\n",
       "      <td>0.712989</td>\n",
       "      <td>0.559717</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>0.556240</td>\n",
       "      <td>1.693099</td>\n",
       "      <td>1</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.976759</td>\n",
       "      <td>0.376580</td>\n",
       "      <td>0.973784</td>\n",
       "      <td>0.604716</td>\n",
       "      <td>0.828846</td>\n",
       "      <td>0.574712</td>\n",
       "      <td>0.628076</td>\n",
       "      <td>0.285576</td>\n",
       "      <td>0.586833</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>6.783459</td>\n",
       "      <td>1</td>\n",
       "      <td>70.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0        x1        x2        x3        x4        x5        x6  \\\n",
       "0           0  0.417022  0.720324  0.000114  0.302333  0.146756  0.092339   \n",
       "1           1  0.019367  0.678836  0.211628  0.265547  0.491573  0.053363   \n",
       "2           2  0.019880  0.026211  0.028306  0.246211  0.860028  0.538831   \n",
       "3           3  0.556240  0.136455  0.059918  0.121343  0.044552  0.107494   \n",
       "4           4  0.000402  0.976759  0.376580  0.973784  0.604716  0.828846   \n",
       "\n",
       "         x7        x8        x9       x10        f1        f2  gen  rank  \n",
       "0  0.186260  0.345561  0.396767  0.538817  0.417022  2.482199    1  58.0  \n",
       "1  0.574118  0.146729  0.589306  0.699758  0.019367  4.408805    1  63.0  \n",
       "2  0.552822  0.842031  0.124173  0.279184  0.019880  4.198771    1  64.0  \n",
       "3  0.225709  0.712989  0.559717  0.012556  0.556240  1.693099    1  52.0  \n",
       "4  0.574712  0.628076  0.285576  0.586833  0.000402  6.783459    1  70.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\\\kevin\\\\OneDrive\\\\Documents\\\\MSU\\\\Sem 4\\\\Capstone\\\\training_data_ZDT1_10var_100gen.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_rank = 30\n",
    "df = data[['x1','x2','x3','x4','x5','x6','x7','x8','x9','x10','rank']]\n",
    "df.loc[df['rank'] < partition_rank, 'near_parito'] = 1\n",
    "df.loc[df['rank'] >= partition_rank, 'near_parito'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 12)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>rank</th>\n",
       "      <th>near_parito</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.417022</td>\n",
       "      <td>0.720324</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.302333</td>\n",
       "      <td>0.146756</td>\n",
       "      <td>0.092339</td>\n",
       "      <td>0.186260</td>\n",
       "      <td>0.345561</td>\n",
       "      <td>0.396767</td>\n",
       "      <td>0.538817</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.678836</td>\n",
       "      <td>0.211628</td>\n",
       "      <td>0.265547</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.053363</td>\n",
       "      <td>0.574118</td>\n",
       "      <td>0.146729</td>\n",
       "      <td>0.589306</td>\n",
       "      <td>0.699758</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.028306</td>\n",
       "      <td>0.246211</td>\n",
       "      <td>0.860028</td>\n",
       "      <td>0.538831</td>\n",
       "      <td>0.552822</td>\n",
       "      <td>0.842031</td>\n",
       "      <td>0.124173</td>\n",
       "      <td>0.279184</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.556240</td>\n",
       "      <td>0.136455</td>\n",
       "      <td>0.059918</td>\n",
       "      <td>0.121343</td>\n",
       "      <td>0.044552</td>\n",
       "      <td>0.107494</td>\n",
       "      <td>0.225709</td>\n",
       "      <td>0.712989</td>\n",
       "      <td>0.559717</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.976759</td>\n",
       "      <td>0.376580</td>\n",
       "      <td>0.973784</td>\n",
       "      <td>0.604716</td>\n",
       "      <td>0.828846</td>\n",
       "      <td>0.574712</td>\n",
       "      <td>0.628076</td>\n",
       "      <td>0.285576</td>\n",
       "      <td>0.586833</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0  0.417022  0.720324  0.000114  0.302333  0.146756  0.092339  0.186260   \n",
       "1  0.019367  0.678836  0.211628  0.265547  0.491573  0.053363  0.574118   \n",
       "2  0.019880  0.026211  0.028306  0.246211  0.860028  0.538831  0.552822   \n",
       "3  0.556240  0.136455  0.059918  0.121343  0.044552  0.107494  0.225709   \n",
       "4  0.000402  0.976759  0.376580  0.973784  0.604716  0.828846  0.574712   \n",
       "\n",
       "         x8        x9       x10  rank  near_parito  \n",
       "0  0.345561  0.396767  0.538817  58.0          0.0  \n",
       "1  0.146729  0.589306  0.699758  63.0          0.0  \n",
       "2  0.842031  0.124173  0.279184  64.0          0.0  \n",
       "3  0.712989  0.559717  0.012556  52.0          0.0  \n",
       "4  0.628076  0.285576  0.586833  70.0          0.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "near_parito\n",
       "1.0    4143\n",
       "0.0     857\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['near_parito'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>x10</th>\n",
       "      <th>rank</th>\n",
       "      <th>near_parito</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.417022</td>\n",
       "      <td>0.720324</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.302333</td>\n",
       "      <td>0.146756</td>\n",
       "      <td>0.092339</td>\n",
       "      <td>0.186260</td>\n",
       "      <td>3.455607e-01</td>\n",
       "      <td>0.396767</td>\n",
       "      <td>0.538817</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.678836</td>\n",
       "      <td>0.211628</td>\n",
       "      <td>0.265547</td>\n",
       "      <td>0.491573</td>\n",
       "      <td>0.053363</td>\n",
       "      <td>0.574118</td>\n",
       "      <td>1.467286e-01</td>\n",
       "      <td>0.589306</td>\n",
       "      <td>0.699758</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019880</td>\n",
       "      <td>0.026211</td>\n",
       "      <td>0.028306</td>\n",
       "      <td>0.246211</td>\n",
       "      <td>0.860028</td>\n",
       "      <td>0.538831</td>\n",
       "      <td>0.552822</td>\n",
       "      <td>8.420309e-01</td>\n",
       "      <td>0.124173</td>\n",
       "      <td>0.279184</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.556240</td>\n",
       "      <td>0.136455</td>\n",
       "      <td>0.059918</td>\n",
       "      <td>0.121343</td>\n",
       "      <td>0.044552</td>\n",
       "      <td>0.107494</td>\n",
       "      <td>0.225709</td>\n",
       "      <td>7.129890e-01</td>\n",
       "      <td>0.559717</td>\n",
       "      <td>0.012556</td>\n",
       "      <td>52.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.976759</td>\n",
       "      <td>0.376580</td>\n",
       "      <td>0.973784</td>\n",
       "      <td>0.604716</td>\n",
       "      <td>0.828846</td>\n",
       "      <td>0.574712</td>\n",
       "      <td>6.280762e-01</td>\n",
       "      <td>0.285576</td>\n",
       "      <td>0.586833</td>\n",
       "      <td>70.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>0.634143</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.000056</td>\n",
       "      <td>0.000260</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000165</td>\n",
       "      <td>2.387473e-06</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>0.493556</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.008155</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>6.652165e-05</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>0.093564</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.000171</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>4.033887e-04</td>\n",
       "      <td>0.000754</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>0.382885</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000019</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>1.388837e-05</td>\n",
       "      <td>0.000591</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>0.077126</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>1.073056e-07</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.000467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x1        x2        x3        x4        x5        x6        x7  \\\n",
       "0     0.417022  0.720324  0.000114  0.302333  0.146756  0.092339  0.186260   \n",
       "1     0.019367  0.678836  0.211628  0.265547  0.491573  0.053363  0.574118   \n",
       "2     0.019880  0.026211  0.028306  0.246211  0.860028  0.538831  0.552822   \n",
       "3     0.556240  0.136455  0.059918  0.121343  0.044552  0.107494  0.225709   \n",
       "4     0.000402  0.976759  0.376580  0.973784  0.604716  0.828846  0.574712   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "4995  0.634143  0.000149  0.000219  0.000056  0.000260  0.000013  0.000165   \n",
       "4996  0.493556  0.000003  0.008155  0.000212  0.005580  0.000034  0.000399   \n",
       "4997  0.093564  0.000397  0.000171  0.000017  0.000237  0.000013  0.000178   \n",
       "4998  0.382885  0.000149  0.000116  0.000019  0.000028  0.000109  0.000255   \n",
       "4999  0.077126  0.000140  0.000463  0.000018  0.000003  0.000087  0.000178   \n",
       "\n",
       "                x8        x9       x10  rank  near_parito  \n",
       "0     3.455607e-01  0.396767  0.538817  58.0          0.0  \n",
       "1     1.467286e-01  0.589306  0.699758  63.0          0.0  \n",
       "2     8.420309e-01  0.124173  0.279184  64.0          0.0  \n",
       "3     7.129890e-01  0.559717  0.012556  52.0          0.0  \n",
       "4     6.280762e-01  0.285576  0.586833  70.0          0.0  \n",
       "...            ...       ...       ...   ...          ...  \n",
       "4995  2.387473e-06  0.000437  0.000004   0.0          1.0  \n",
       "4996  6.652165e-05  0.000220  0.000344   1.0          1.0  \n",
       "4997  4.033887e-04  0.000754  0.000121   0.0          1.0  \n",
       "4998  1.388837e-05  0.000591  0.000060   0.0          1.0  \n",
       "4999  1.073056e-07  0.000227  0.000467   0.0          1.0  \n",
       "\n",
       "[5000 rows x 12 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.reindex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['rank','near_parito'])\n",
    "y = df.near_parito.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       0\n",
      "2       0\n",
      "3       0\n",
      "4       0\n",
      "       ..\n",
      "4995    1\n",
      "4996    1\n",
      "4997    1\n",
      "4998    1\n",
      "4999    1\n",
      "Name: near_parito, Length: 5000, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3350, 10) (3350,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape , y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,929</span> (19.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,929\u001b[0m (19.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,929</span> (19.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,929\u001b[0m (19.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import layers\n",
    "# from keras.models import Sequential\n",
    "# from keras.layers import Dense\n",
    "\n",
    "# inputs = keras.Input(shape=(10,), name=\"features\")\n",
    "# x = layers.Dense(64, activation=\"relu\", name=\"dense_1\")(inputs)\n",
    "# x = layers.Dense(64, activation=\"relu\", name=\"dense_2\")(x)\n",
    "# outputs = layers.Dense(1, activation=\"sigmoid\", name=\"predictions\")(x)\n",
    "model = keras.Sequential()\n",
    "model.add(layers.Dense(64, activation=\"relu\",input_shape = (10,)))\n",
    "model.add(layers.Dense(64, activation=\"relu\"))\n",
    "model.add(layers.Dense(1, 'sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN | means applying SGD on the whole ANN\n",
    "model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.9181 - loss: 0.3588\n",
      "Epoch 2/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9869 - loss: 0.0389\n",
      "Epoch 3/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9899 - loss: 0.0248\n",
      "Epoch 4/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9922 - loss: 0.0230\n",
      "Epoch 5/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9896 - loss: 0.0250\n",
      "Epoch 6/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9930 - loss: 0.0212\n",
      "Epoch 7/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9928 - loss: 0.0174\n",
      "Epoch 8/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9929 - loss: 0.0220\n",
      "Epoch 9/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0183\n",
      "Epoch 10/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 965us/step - accuracy: 0.9934 - loss: 0.0209\n",
      "Epoch 11/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9923 - loss: 0.0188\n",
      "Epoch 12/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9955 - loss: 0.0139\n",
      "Epoch 13/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9955 - loss: 0.0154\n",
      "Epoch 14/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0132\n",
      "Epoch 15/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0121\n",
      "Epoch 16/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9960 - loss: 0.0114\n",
      "Epoch 17/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9941 - loss: 0.0133\n",
      "Epoch 18/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0144\n",
      "Epoch 19/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 939us/step - accuracy: 0.9970 - loss: 0.0095\n",
      "Epoch 20/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9956 - loss: 0.0109\n",
      "Epoch 21/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0098\n",
      "Epoch 22/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0080\n",
      "Epoch 23/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0095\n",
      "Epoch 24/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0080\n",
      "Epoch 25/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0097\n",
      "Epoch 26/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0079\n",
      "Epoch 27/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9980 - loss: 0.0089\n",
      "Epoch 28/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0073\n",
      "Epoch 29/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0092\n",
      "Epoch 30/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9942 - loss: 0.0111\n",
      "Epoch 31/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9964 - loss: 0.0091\n",
      "Epoch 32/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9955 - loss: 0.0123\n",
      "Epoch 33/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0087\n",
      "Epoch 34/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9972 - loss: 0.0087\n",
      "Epoch 35/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0080\n",
      "Epoch 36/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9973 - loss: 0.0067\n",
      "Epoch 37/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9960 - loss: 0.0112\n",
      "Epoch 38/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9977 - loss: 0.0063\n",
      "Epoch 39/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9977 - loss: 0.0079\n",
      "Epoch 40/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0052\n",
      "Epoch 41/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0060\n",
      "Epoch 42/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0068\n",
      "Epoch 43/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 948us/step - accuracy: 0.9965 - loss: 0.0079\n",
      "Epoch 44/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0082\n",
      "Epoch 45/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9982 - loss: 0.0050\n",
      "Epoch 46/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0068\n",
      "Epoch 47/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9967 - loss: 0.0088\n",
      "Epoch 48/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 937us/step - accuracy: 0.9975 - loss: 0.0057\n",
      "Epoch 49/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9964 - loss: 0.0080\n",
      "Epoch 50/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9969 - loss: 0.0060\n",
      "Epoch 51/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9962 - loss: 0.0093\n",
      "Epoch 52/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9938 - loss: 0.0114\n",
      "Epoch 53/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9982 - loss: 0.0061\n",
      "Epoch 54/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0058\n",
      "Epoch 55/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9987 - loss: 0.0067\n",
      "Epoch 56/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9984 - loss: 0.0061\n",
      "Epoch 57/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9981 - loss: 0.0057\n",
      "Epoch 58/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9952 - loss: 0.0090\n",
      "Epoch 59/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9972 - loss: 0.0073\n",
      "Epoch 60/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9966 - loss: 0.0073\n",
      "Epoch 61/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0073\n",
      "Epoch 62/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9968 - loss: 0.0084\n",
      "Epoch 63/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0061\n",
      "Epoch 64/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9957 - loss: 0.0076\n",
      "Epoch 65/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9971 - loss: 0.0051\n",
      "Epoch 66/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9970 - loss: 0.0070\n",
      "Epoch 67/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9963 - loss: 0.0081\n",
      "Epoch 68/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9978 - loss: 0.0054\n",
      "Epoch 69/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9974 - loss: 0.0053\n",
      "Epoch 70/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0035\n",
      "Epoch 71/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9983 - loss: 0.0048\n",
      "Epoch 72/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9971 - loss: 0.0058\n",
      "Epoch 73/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9984 - loss: 0.0041\n",
      "Epoch 74/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9979 - loss: 0.0048\n",
      "Epoch 75/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9968 - loss: 0.0057\n",
      "Epoch 76/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0043\n",
      "Epoch 77/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0045\n",
      "Epoch 78/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9994 - loss: 0.0028\n",
      "Epoch 79/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9969 - loss: 0.0059\n",
      "Epoch 80/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9976 - loss: 0.0054\n",
      "Epoch 81/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9971 - loss: 0.0048\n",
      "Epoch 82/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9984 - loss: 0.0059\n",
      "Epoch 83/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9989 - loss: 0.0034\n",
      "Epoch 84/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9992 - loss: 0.0029\n",
      "Epoch 85/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9990 - loss: 0.0027\n",
      "Epoch 86/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9988 - loss: 0.0031\n",
      "Epoch 87/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9988 - loss: 0.0033\n",
      "Epoch 88/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9981 - loss: 0.0040\n",
      "Epoch 89/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9972 - loss: 0.0077\n",
      "Epoch 90/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.9983 - loss: 0.0033\n",
      "Epoch 91/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9988 - loss: 0.0030\n",
      "Epoch 92/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9977 - loss: 0.0046\n",
      "Epoch 93/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9995 - loss: 0.0020\n",
      "Epoch 94/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9966 - loss: 0.0052\n",
      "Epoch 95/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9978 - loss: 0.0056\n",
      "Epoch 96/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - accuracy: 0.9990 - loss: 0.0033\n",
      "Epoch 97/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9979 - loss: 0.0033\n",
      "Epoch 98/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9959 - loss: 0.0084\n",
      "Epoch 99/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.9986 - loss: 0.0031\n",
      "Epoch 100/100\n",
      "\u001b[1m335/335\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9973 - loss: 0.0088\n",
      "{'accuracy': [0.9614925384521484, 0.9889551997184753, 0.9895522594451904, 0.9925373196601868, 0.9922388195991516, 0.9928358197212219, 0.9937313199043274, 0.9928358197212219, 0.9946268796920776, 0.9949253797531128, 0.9946268796920776, 0.9955223798751831, 0.9955223798751831, 0.995223879814148, 0.9949253797531128, 0.9958208799362183, 0.9946268796920776, 0.9964179396629333, 0.9967164397239685, 0.995223879814148, 0.9967164397239685, 0.9967164397239685, 0.9961193799972534, 0.9964179396629333, 0.9961193799972534, 0.9946268796920776, 0.997611939907074, 0.9958208799362183, 0.9970149397850037, 0.995223879814148, 0.9961193799972534, 0.9967164397239685, 0.9964179396629333, 0.9967164397239685, 0.9973134398460388, 0.9967164397239685, 0.995223879814148, 0.9961193799972534, 0.9958208799362183, 0.9973134398460388, 0.9970149397850037, 0.9958208799362183, 0.9967164397239685, 0.9973134398460388, 0.9973134398460388, 0.9967164397239685, 0.997611939907074, 0.9973134398460388, 0.9964179396629333, 0.9970149397850037, 0.9970149397850037, 0.9964179396629333, 0.9970149397850037, 0.9964179396629333, 0.9982089400291443, 0.997611939907074, 0.9979104399681091, 0.9967164397239685, 0.9979104399681091, 0.997611939907074, 0.9973134398460388, 0.9967164397239685, 0.9982089400291443, 0.9973134398460388, 0.9973134398460388, 0.9973134398460388, 0.9979104399681091, 0.9973134398460388, 0.997611939907074, 0.9988059997558594, 0.9973134398460388, 0.9985074400901794, 0.997611939907074, 0.9979104399681091, 0.9973134398460388, 0.9988059997558594, 0.9982089400291443, 0.9988059997558594, 0.997611939907074, 0.9982089400291443, 0.9970149397850037, 0.9985074400901794, 0.9979104399681091, 0.9988059997558594, 0.9985074400901794, 0.9979104399681091, 0.9982089400291443, 0.9982089400291443, 0.9982089400291443, 0.9982089400291443, 0.9982089400291443, 0.9979104399681091, 0.9988059997558594, 0.997611939907074, 0.9982089400291443, 0.9979104399681091, 0.9988059997558594, 0.997611939907074, 0.9979104399681091, 0.9979104399681091], 'loss': [0.17985329031944275, 0.03312285989522934, 0.027811357751488686, 0.023042555898427963, 0.02223934978246689, 0.020493989810347557, 0.01887219399213791, 0.01773647964000702, 0.017573583871126175, 0.015715010464191437, 0.015185397118330002, 0.01351203303784132, 0.013688136823475361, 0.012971489690244198, 0.012492918409407139, 0.011731674894690514, 0.01253450196236372, 0.012208103202283382, 0.01100140530616045, 0.011630612425506115, 0.010510917752981186, 0.010526423342525959, 0.010108466260135174, 0.009631643071770668, 0.009579967707395554, 0.011538282968103886, 0.009253048337996006, 0.009829924441874027, 0.009242178872227669, 0.010809743776917458, 0.009729426354169846, 0.009974776767194271, 0.008818334899842739, 0.009221268817782402, 0.008410153910517693, 0.008572207763791084, 0.010468647815287113, 0.00791260041296482, 0.01002301275730133, 0.007582716643810272, 0.008171958848834038, 0.009499947540462017, 0.008082940243184566, 0.0077523523941636086, 0.006701335776597261, 0.007841401733458042, 0.00733532477170229, 0.0068608662113547325, 0.009591792710125446, 0.006778651382774115, 0.006790269166231155, 0.007962997071444988, 0.006917564198374748, 0.007238560356199741, 0.006901167333126068, 0.006636110134422779, 0.005567045416682959, 0.006384129170328379, 0.005845294333994389, 0.006124529987573624, 0.006397606804966927, 0.00694475369527936, 0.00600154884159565, 0.005515750963240862, 0.0058369943872094154, 0.005647839978337288, 0.006046994123607874, 0.005803475622087717, 0.005128158256411552, 0.004061317536979914, 0.0067834085784852505, 0.0044394503347575665, 0.005505550652742386, 0.004898557905107737, 0.00445017172023654, 0.004821553360670805, 0.004484472330659628, 0.0035742055624723434, 0.005886432249099016, 0.0054026274010539055, 0.005521700251847506, 0.004887668415904045, 0.005293736699968576, 0.0033393714111298323, 0.0033888269681483507, 0.004124305676668882, 0.004708540625870228, 0.004362832754850388, 0.0044798175804317, 0.004010971635580063, 0.004205646924674511, 0.004739876836538315, 0.0037761153653264046, 0.005014307331293821, 0.0045042457059025764, 0.004320780746638775, 0.0028868759982287884, 0.005200039129704237, 0.003955722786486149, 0.005545510910451412]}\n",
      "Evaluate on test data\n",
      "\u001b[1m13/13\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9956 - loss: 0.0110  \n",
      "test loss, test acc: [0.010249372571706772, 0.9957575798034668]\n",
      "Generate predictions for 3 samples\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
      "predictions shape: (3, 1)\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "history = model.fit(X_train, y_train, batch_size = 10, epochs = 100)\n",
    "\n",
    "print(history.history)\n",
    "# Evaluate the model on the test data using `evaluate`\n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_test, y_test, batch_size=128)\n",
    "print(\"test loss, test acc:\", results)\n",
    "\n",
    "# Generate predictions (probabilities -- the output of the last layer)\n",
    "# on new data using `predict`\n",
    "print(\"Generate predictions for 3 samples\")\n",
    "predictions = model.predict(X_test[:3])\n",
    "print(\"predictions shape:\", predictions.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 975us/step - accuracy: 0.9956 - loss: 0.0108\n"
     ]
    }
   ],
   "source": [
    "loss, acc = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010215070098638535 0.9957575798034668\n"
     ]
    }
   ],
   "source": [
    "print(loss,acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">704</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │           \u001b[38;5;34m704\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m4,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m65\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">14,789</span> (57.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m14,789\u001b[0m (57.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,929</span> (19.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,929\u001b[0m (19.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,860</span> (38.52 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m9,860\u001b[0m (38.52 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inverser DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2112 - val_loss: 0.1077\n",
      "Epoch 2/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0967 - val_loss: 0.0485\n",
      "Epoch 3/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0424 - val_loss: 0.0200\n",
      "Epoch 4/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0207 - val_loss: 0.0133\n",
      "Epoch 5/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0150 - val_loss: 0.0107\n",
      "Epoch 6/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0115 - val_loss: 0.0091\n",
      "Epoch 7/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0121 - val_loss: 0.0076\n",
      "Epoch 8/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0118 - val_loss: 0.0069\n",
      "Epoch 9/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - val_loss: 0.0067\n",
      "Epoch 10/10\n",
      "\u001b[1m84/84\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 0.0085 - val_loss: 0.0062\n",
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Define the original DNN to predict Y from X\n",
    "def create_original_model(input_dim, output_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dense(8, activation='relu'),\n",
    "        Dense(output_dim, activation='sigmoid')  # Use sigmoid activation for binary classification\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Define the inverse DNN to predict X from Y\n",
    "def create_inverse_model(input_dim, output_dim):\n",
    "    model = tf.keras.Sequential([\n",
    "        Dense(8, activation='relu', input_shape=(output_dim,)),\n",
    "        Dense(64, activation='relu'),\n",
    "        Dense(input_dim, activation='linear')  # Use linear activation for regression\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "# Assuming you have data X_train, y_train\n",
    "input_dim = 10\n",
    "output_dim = 1\n",
    "\n",
    "# Instantiate and train the original model\n",
    "original_model = create_original_model(input_dim, output_dim)\n",
    "original_model.compile(optimizer='adam', loss='mse')\n",
    "original_model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Extract the trained weights from the original model\n",
    "original_weights = original_model.get_weights()\n",
    "\n",
    "\n",
    "# Instantiate the inverse model\n",
    "inverse_model = create_inverse_model(input_dim, output_dim)\n",
    "inverse_model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# for i in range(len(original_model.layers)):\n",
    "#     print(i,tf.transpose(original_model.layers[i].get_weights()[1]).shape)\n",
    "# for i in range(len(inverse_model.layers)):\n",
    "#     print(i, inverse_model.layers[i].get_weights()[1].shape)\n",
    "\n",
    "\n",
    "# Set the weights of the inverse model to the transpose of the original model's weights\n",
    "for i in range(len(inverse_model.layers)-1):\n",
    "    # print(i, inverse_model.layers[i].get_weights()[1].shape)\n",
    "    # print(inverse_model.layers[i].get_weights()[0])\n",
    "    # print(original_model.layers[2-i].get_weights()[0].transpose())\n",
    "    inverse_model.layers[i].set_weights([ original_model.layers[2-i].get_weights()[0].transpose(), np.random.rand(len(inverse_model.layers[i].get_weights()[1]))])\n",
    "\n",
    "# Now, you can use the inverse model to predict X from Y\n",
    "predicted_X = inverse_model.predict(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1501    1\n",
      "2586    1\n",
      "2653    1\n",
      "1055    1\n",
      "705     1\n",
      "       ..\n",
      "908     1\n",
      "2114    1\n",
      "3896    1\n",
      "1627    1\n",
      "2873    1\n",
      "Name: near_parito, Length: 1650, dtype: int32\n"
     ]
    }
   ],
   "source": [
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5569209 ,  0.16628669,  0.03074656, ...,  0.20487428,\n",
       "        -0.6698824 , -1.3110658 ],\n",
       "       [ 1.5569209 ,  0.16628669,  0.03074656, ...,  0.20487428,\n",
       "        -0.6698824 , -1.3110658 ],\n",
       "       [ 1.5569209 ,  0.16628669,  0.03074656, ...,  0.20487428,\n",
       "        -0.6698824 , -1.3110658 ],\n",
       "       ...,\n",
       "       [ 1.5569209 ,  0.16628669,  0.03074656, ...,  0.20487428,\n",
       "        -0.6698824 , -1.3110658 ],\n",
       "       [ 1.5569209 ,  0.16628669,  0.03074656, ...,  0.20487428,\n",
       "        -0.6698824 , -1.3110658 ],\n",
       "       [ 1.5569209 ,  0.16628669,  0.03074656, ...,  0.20487428,\n",
       "        -0.6698824 , -1.3110658 ]], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m52/52\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.9999999],\n",
       "       [0.9999999],\n",
       "       [0.9999999],\n",
       "       ...,\n",
       "       [0.9999999],\n",
       "       [0.9999999],\n",
       "       [0.9999999]], dtype=float32)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_model.predict(predicted_X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
